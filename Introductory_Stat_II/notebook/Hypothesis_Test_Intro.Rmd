---
title: 'Teste de Hipóteses: Introdução'
author: "Fernando B. Sabino da Silva"
output:
  slidy_presentation:
    css: https://asta.math.aau.dk/course/asta/2018-1/?file=lecture_style.css
    fig_caption: no
    highlight: tango
    theme: cerulean
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    fig_caption: no
    highlight: tango
    number_section: yes
    toc: yes
---

```{r, include = FALSE}
## Remember to add all packages used in the code below!
missing_pkgs <- setdiff(c("mosaic"), rownames(installed.packages()))
if(length(missing_pkgs)>0) install.packages(missing_pkgs)
```

# Inferência Estatística: Hipóteses e teste
## Conceito de hipóteses

* Uma **hipótese** é uma afirmação sobre uma dada população. Geralmente, é uma declaração sobre o valor de um parâmetro populacional (ou sobre o intervalo onde eles estão).
* Exemplos:
    * Controle de qualidade de produtos: Uma hipótese é que os produtos tenham, por exemplo, um determinado peso, um determinado consumo de energia ou uma determinada durabilidade mínima.
    * Economia:  Por exemplo, não há dependência entre a idade de uma empresa e o nível de retorno.

## Teste de significância
* Um teste de significância é usado para investigar se os dados contradizem uma hipótese ou não. Lembre-se do que estudamos sobre distribuições amostrais. A ideia aqui é usar as informações de maneira efetiva para poder tomar decisões mais educadas e com maior precisão.
* Se a hipótese diz que um parâmetro assume determinado valor, então o teste deve dizer qual a probabilidade de que uma determinada amostra retirada desta população hipotética gere uma amostra com as características encontradas. Exemplo: Se $\mu = 10$, qual a probabilidade de que uma amostra retirada desta população apresente $\bar{X}_n = 8$? Se a probabilidade for grande, não iremos descartar a hipótese e diremos (ficará mais claro adiante) que "não há evidências suficientes para que rejeitemos a hipótese". Se a probabilidade for pequena, fará mais sentido imaginarmos que a amostra foi retirada de outra população (não foi retirada da hipotética). Qual população? Uma que tenha mais probabilidade de ter gerado aquela amostra.

* Exemplos:
    * Tempo de espera em uma fila. Nós coletamos uma amostra de $n$ clientes e contamos quantos esperaram mais de 5 minutos. A política da empresa é de que no máximo $10\%$ dos clientes devem esperar mais do que 5 minutos. Em uma amostra de tamanho $n=32$, nós observamos 4 com tempo de espera superior a 5 minutos, i.e. a proporção estimada é de
        $\hat{p} = \frac{4}{32} = 12.5\%$. Sabendo que $\hat{p}$ depende da amostra, podemos nos perguntar se o valor encontrado é significativamente diferente de $10\%$? Em outras palavras, se a proporção populacional é de fato $10\%$, qual a probabilidade de encontrarmos $12.5\%$ em uma amostra de 32 clientes?
    * O nível de álcool no sangue de um estudante é medido 4 vezes e apresenta os seguintes valores $0.504,0.500,0.512,0.524$, i.e. a média estimada é $\bar{y}=0.51$. Isto é muito diferente de, digamos, um limite de $0.5$?

## Hipótese nula e alternativa

* **A hipótese nula** - denotada por $H_0$ - geralmente especifica que um parâmetro da população tem algum valor determinado. Por exemplo, se $\mu$ é a média do nível de álcool no sangue, nós podemos escrever a hipótese nula como 
    * $H_0 : \mu = 0.5$.
* A **hipótese alternativa** - denotada por $H_1$ - especifica que o parâmetro populacional está contido em um conjunto de valores diferentes do especificado na hipótese nula. Por exemplo, 
    * a hipótese nula é $H_0 : \mu = 0.5$
    * a hipótese alternativa é $H_1 : \mu \neq 0.5$.
    
* A **hipótese alternativa** - denotada $H_1$ - geralmente especifica que o parâmetro populacional está contido em um dado conjunto de valores diferentes da hipótese nula. Por exemplo, se $\mu$ é a média populacional de uma medição do nível de álcool no sangue,
* a hipótese nula é $H_0: \mu = 0.5$
* a hipótese alternativa é $H_1: \mu \neq 0.5$.



## Estatística de teste

* Considere um parâmetro populacional $\mu$ e 
  $$
  H_0:\mu = \mu_0,
  $$
  onde $\mu_0$ é um número conhecido, digamos, \ $\mu_0 = 0.5$.
* Com base na amostra, nós temos uma estimativa $\hat{\mu}$.
* Uma **estatística de teste** $T$ dependerá tipicamente de $\hat{\mu}$ e
  $\mu_0$ (podemos escrever $T(\hat{\mu}, \mu_0)$) e medirá quão "longe $\hat{\mu}$ está de $\mu_0$"
* Frequentemente nós usamos $T(\hat{\mu},\mu_0)$ = "o número de desvios padrão entre $\hat{\mu}$
          e $\mu_0$".
* Por exemplo, é improvável que a distância esteja acima de 3 desvios padrão. Se isto acontecer $\mu_0$ não será provavelmente o valor correto do parâmetro (populacional).
  
## $P$-valor

* Nós consideramos
    * $H_0$:\ uma hipótese nula.
    * $H_1$:\ uma hipótese alternativa.
    * $T$:\ uma estatística de teste, onde o valor calculado com base na amostra atual é denotado por $t_{obs}$.
* Para investigar a plausibilidade de $H_0$, nós medimos a evidência de $H_0$ usando o que chamamos de $p$-valor:
    * O $p$-valor é a probabilidade de se observar um valor mais extremo $T \geq t_{obs}$ (se repetíssemos o experimento) 
    *sob a suposição de que 
      $H_0$ seja verdadeira*, isto é, calculamos a probabilidade condicional de obter um valor mais extremo do que $t_{obs}$ (dependendo da hipótese do que o valor absoluto de $t_{obs}$) quando a hipótese nula é verdadeira.
    * Se o $p$-valor é pequeno, então haverá evidências de que a nula não seja verdadeira, pois existe uma probabilidade pequena de observar um valor mais extremo do que $t_{obs}$ se $H_0$ for verdadeira. Podemos concluir que      $$
      \textbf{Quanto menor for o  $p$-valor, maior será a evidência contrária a $H_0$.} 
      $$
* Mas o que é um valor pequeno para o $p$-valor? Isto depende do **tamanho da amostra** e de outras considerações que não iremos ver neste curso. Se o $p$-valor for abaixo de $5\%$ dizemos que o valor da estatística de teste ($t_{obs}$) é **significante** ao nível de $5\%$.


## Nível de significância

* Nós consideramos
    * $H_0$: uma hipótese nula.
    * $H_1$: uma hipótese alternativa.
    * $T$: uma estatística de teste, onde o valor calculado baseado na amostral atual é denotedo por $t_{obs}$ é o correspondente $p$-valor é simplesmente $p$ (ou $p_{obs}$).
* Na prática, nós usualmente queremos usar as informações para uma tomada de decisão. Em outras palavras, nós queremos decidir se vamos ou não rejeitar $H_0$.
* A decisão dentro deste framework pode ser feita se nós estabelecermos de antemão o chamado **nível de significância $\alpha$**, onde 
    * $\alpha$ é uma dada percentagem
    * nós rejeitamos $H_0$, se $p$ for menor ou igial a $\alpha$
    * $\alpha$ é chamado de **nível de significância** do teste
    * valores típicos de $\alpha$ são $5\%$ ou $1\%$.

## Teste de significância para a média

### Teste $t$ (bilateral) para a média:

* Assuma que retiramos uma amostra de uma população com distribuição $\texttt{N}(\mu,\sigma^{2})$.
* As estimativas dos parâmetros populacionais são $\hat{\mu}=\bar{y}$ e 
$\hat{\sigma}=s$ com base em $n$ observações.
* Hipótese nula:\ $H_0:\ \mu = \mu_0$, onde $\mu_0$ é um valor conhecido.
* **Hipótese alternativa bilateral**:\  $H_1:\ \mu \neq \mu_0$.
* Estatística de teste observada:\ $t_{obs} = \frac{\bar{y} - \mu_0}{ep(\bar{y})}$, onde
  $ep(\bar{y}) = \frac{s}{\sqrt{n}}$.
*  I.e.\ $t_{obs}$ mede quantos desvios padrao (com sinal $\pm$) a média empírica está afastada de $\mu_0$.
* Se $H_0$ é verdadeira (sob $H_0$),  $t_{obs}$ é uma observação retirada de uma população com distribuição $t$ com $df = n - 1$ graus de liberdade
* $P$-valor = 2 x "probabilidade da cauda superior de
  $|t_{obs}|$". A probabilidade é calculada usando a distribuição $t$ com $df$ graus de liberdade, onde $df = n - 1$, pois perdemos um grau de liberdade ao estimar $\bar{y}$.

----

### Exemplo: Teste $t$ bilateral
* Medições do nível de álcool no sangue: $0.504, 0.500, 0.512, 0.524$.
* Assuma que a amostra foi retirada de uma população com distribuição normal .
* Nós calculamos
    * $\bar{y} = 0.51$ and $s = 0.0106$
    * $ep_{\bar{y}} = \frac{s}{\sqrt{n}} = \frac{0.0106}{\sqrt{4}} = 0.0053$
    * $H_0: \mu = 0.5$,\ i.e.\ $\mu_0 = 0.5$
    * $t_{obs} = \frac{\bar{y}-\mu_0}{ep_\bar{y}} = \frac{0.51-0.5}{0.0053} = 1.89$
* Portanto, estamos a quase 2 desvios padrão de $0.5$.\ Isso é um valor extremo em uma distribuição $t$ com 3 graus de liberdade?

```{r message=FALSE}
library(mosaic)
1 - pdist("t", q = 1.89, df = 3)
```

* O $p$-valor é 2$\cdot$ `r round(abs(pt(-1.89, df = 3)),3)`,\  i.e. mais do que $15$\% se a hipótese alternativa for bilateral. Com base nisso, nós não rejeitamos $H_0$.



## Teste $t$ unilateral para a média

Todo o nível de significância será colocado em um lado apenas, tal como um limite inferior ou superior de confiança. Veja mais exemplos no livro do Costa Neto.



## Visão geral do teste $t$

  ![](https://asta.math.aau.dk/static-files/asta/img/t-testOversigt.jpg)

## Teste de significância para a proporção

* Considere uma amostra de tamanho $n$, onde observamos se uma determinada propriedade está presente ou não.
* A frequência relativa desta propriedade na população é $p$, estimada por $\hat{p}$.
* Hipotése Nula:\ $H_0: p = p_0$, onde $p_0$ é um número conhecido.
* **Alternativa bilateral**:\ $H_1: p \neq p_0$.
* *Se $H_0$ é verdadeira* o erro padrão $\hat{p}$ é dado por $ep_0 = \sqrt{\frac{p_0(1-p_0)}{n}}$.
* Estatística de teste observada: $z_{obs} = \frac{\hat{p}-p_0}{ep_0}$
* I.e. $z_{obs}$ mede quantos desvios padrão há entre $\hat{p}$ to $p_0$.

----


### Teste Aproximado

* Se $n\hat{p}$ e $n(1 - \hat{p})$ são maiores do que $5$, nós sabemos que $\hat{p}$ segue aproximadamente uma distribuição normal, i.e.
    * Se $H_0$ é verdadeira e a amostra é grande o suficiente, então $z_{obs}$ é uma observação de uma distribuição normal padrão.
* $P$-valor = 2 x "probabilidade da cauda superior de $|z_{obs}|$". A probabilidade é calculada usando a distribuição normal padrão.

----

### Exemplo: Teste Aproximado
* Considere o seguinte estudo:
    * Uma amostra aleatória de 1200 indivíduos (Florida, 2006) foi consultada se preferiam menos serviços ou aumentos de impostos.
    * 52% preferiam aumentos de impostos. Isto é suficiente para dizer que a proporção é significativamente diferente de 0.5 ?
* Amostra com $n = 1200$ observações e proporção
  $\hat{p} = 0.52$. 
* Hipotése Nula $H_0: p = 0.5$.
* Hipótese Alternativa $H_1: p \neq 0.5$.
* Erro padrão
  $ep_0 = \sqrt{\frac{p_0(1-p_0)}{n}} = \sqrt{\frac{0.5\times0.5}{1200}} = 0.0144$
* Estatística de teste observada
  $z_{obs} = \frac{\hat{p}-p_0}{ep_0}=\frac{0.52-0.5}{0.0144}=1.39$
* "A cauda superior para $1.39$" na distribuição normal padrão é 0.0823, i.e. o
  $p$-valor é 2$\cdot$ 0.0823$=$ 16.46%.
* Conclusão: Não há evidências suficientes para rejeitar $H_0$, i.e. nós não rejeitamos que a preferência na população é de 50%.
* Os cálculos acima também podem ser calculados automaticamente no **R** por 
  (os resultados são um pouco diferentes, devido aos arredondamentos feitos acima):
  
```{r}
count <- 1200 * 0.52 # número de pessoas que preferem o aumento de imposto
prop.test(x = count, n = 1200, correct = F)
```

----

### Teste Binomial (exato)

* Considere novamente uma amostra de tamanho $n$, onde observamos se uma determinada propriedade está presente ou não.
* A frequência relativa da propriedade na população é $p$, estimada por $\hat{p}$.
* Let $y_+=n\hat{p}$ a frequência (contagem total) da propriedade na amostra.
* Pode ser mostrado que $y_+$ segue a **distribuição binomial** com parâmetros $n$ e probabilidade de sucesso $p$.
  Usamos $Bin(n,p)$ para denotar esta distribuição.
* Hipótese nula:\ $H_0: p=p_0$, onde $p_0$ é um número conhecido.
* Hipótese alternativa:\ $H_1: p \neq p_0$.
* $P$-valor para o teste binomial **bilateral**:
    * Se $y_+\geq np_0$:\ 2 x "probabilidade na cauda superior para $y_+$ na distribuição $Bin(n,p_0)$.
    * Se $y_+< np_0$:\ 2 x "probabilidade na cauda superior para $y_+$" na distribuição $Bin(n,p_0)$.

----

### Exemplo: Teste Binomial

* Experimento com $n=30$, onde obtivemos $y_+=14$ sucessos.
* Queremos testar $H_0: p=0.3$ vs.\ $H_1: p \not=0.3$.
* Como $y_+>np_0=9$, usamos a probabilidade de cauda superior correspondente à soma das alturas das
linhas vermelhas à direita de $14$ no gráfico abaixo. (O gráfico continua no lado direito acima de $n=30$, mas foi cortado para fins ilustrativos.)
* A probabilidade da cauda superior de $14$ para cima (i.e. maior do que $13$) é:
```{r}
lower_tail <- pdist("binom", q = 13, size = 30, prob = 0.3)
1 - lower_tail
```
* O $p$-valor é então 2 x `r round(1-lower_tail, 2)` = `r 2 * round(1-lower_tail, 2)`.

----

### Teste Binomial no **R**
* Voltemos aos dados do Chile, onde novamente olhamos a variável `sex`. 
* Vamos testar se a proporção de mulheres é diferente de 0.5, i.e., queremos testar  $H_0:\ p=0.5$ and $H_1:\ p \neq 0.5$, onde $p$ é a proporção populacional desconhecida de mulheres.
```{r}
Chile <- read.delim("C://Users//fsabino//Desktop//Codes//papers//Introductory_Stat_II//notebook//Chile.txt")
binom.test( ~ sex, data = Chile, p = 0.5, conf.level = 0.95)
```
* O $p$-valor para o teste exato (usando a distribuição binomial) é de $27\%$, portanto não há uma diferença significativa entre a proporção de homens e mulheres. 
* O teste aproximado tem um valor $p$ de $26\%$, que pode ser calculado pelo comando
```{r eval = F}
prop.test( ~ sex, data = Chile, p = 0.5, conf.level = 0.95, correct = FALSE)
```
(observe o argumento adicional `correct = FALSE`).

## Visão Geral dos testes para média e proporção
![](https://asta.math.aau.dk/static-files/asta/img/AGRoversigt.jpg)


## Regressando (variável resposta) e regressores (variáveis explicativas)

* Realizamos um experimento, no qual escolhemos aleatoriamente 50 empresas de TI e 50 empresas de serviços e medimos as suas tacas de lucro. Existe associação entre o tipo de empresa (TI/serviço) e a taxa de lucro? 
* Em outras palavras, nós queremos comparar amostras de 2 populações diferentes. Para cada empresa registramos:
    * A variável binária `tipo da empresa`: chamamos de **regressor ou variável explicativa**. Ela divide os dados em 2 grupos.
    * A variável quantitativa `taxa de lucro`: chamamos de
      **regressando ou variável resposta**.



## Amostras dependentes/independentes

* No exemplo com a taxa de lucro das 50 empresas de TI e 50 empresas de serviços, nós temos
 **amostras independentes**, uma vez que a mesma empresa não pode estar em ambos os grupos.
* Agora, pense em outro tipo de experimento, onde escolhemos aleatoriamente 50 empresas de TI e medimos as suas taxas de lucro em 2009 e 2010. Então, podemos estar interessados em saber se há associação entre o ano e a taxa de lucro.
* Neste exemplo, nós temos **amostras dependentes**, uma vez que a mesma companhia está em ambos os grupos.
* Nos referimos, costumeiramente, a amostras dependentes como **amostras pareadas**. 


## Comparação de 2 médias

* Consideremos a situação em que temos duas amostras de variáveis quantitativas:
    * População $1$ tem média $\mu_1$, que é estimada por
      $\hat{\mu}_1=\bar{y}_1$ com base em uma amostra de tamanho $n_1$.
    * População 2 tem média $\mu_2$, que é estimada por       $\hat{\mu}_2=\bar{y}_2$ com base em uma amostra de tamanho $n_2$.
    * Estamos interessados na diferença $\mu_2-\mu_1$, que é estimada por
      $d=\bar{y}_2-\bar{y}_1$.
    * Suponha que queremos encontrar o **eerro padrão estimado**
      $ep_d$ da diferença e que isto tem $df$ graus de liberdade.
    * Suponha que as amostras sejam grandes ou que sejam provenientes de populações com distribuição normal. 
* Então podemos construir um 
    * intervalo de confiança para a diferença, i.e.,
      $$
      (\bar{y}_2-\bar{y}_1)\pm t_{crit}ep_d,
      $$ 
      onde o escore crítico $t$, $t_{crit}$, determina o nível de confiança.
    * teste de significância:
          * para a hipótese nula $H_0:\ \mu_2-\mu_1=0$ e a hipótese alternativa 
          $H_1:\ \mu_2-\mu_1\neq 0$.
          * usamos a estatística de teste:\ $t_{obs} = \frac{\bar{y}_2-\bar{y}_1}{ep_d}$, que tem que ser avaliada em uma distribuição $t$ com $df$ graus de liberdade.


## Comparação de duas médias: Amostras independentes
* Na situação em que as amostras são independentes pode ser demonstrado que
  $$
  ep_d=\sqrt{ep_1^2+ep_2^2},
  $$
  onde $ep_1$ e $ep_2$ são erros padrão estimados para as médias amostrais nas populações $1$ e 2, respectivamente.
* Relembre que neste caso nós temos $ep=\frac{s}{\sqrt{n}}$, i.e.
   $$
   ep_d=\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}},
   $$
   onde $s_1$ e $s_2$ são desvios padrão estimados para as populações $1$ e 
   2, respectivamente.
* Veja os **graus de liberdade** no capítulo 5 de Costa Neto.
<!-- * Para o intervalo de confiança and the significance test we -->
<!--   note that: -->
<!--     * If both $n_1$ and $n_2$ are above 30, then we can use the standard normal  -->
<!--       distribution ($z$-score) rather than the $t$-distribution ($t$-score). -->
<!--     * If $n_1$ or $n_2$ are below 30, then we let **R**  -->
<!--       calculate the graus de liberdade and $p$-valor/intervalo de confiança. -->



## Exemplo: Comparando duas médias (amostras independentes)
Voltamos aos dados do `Chile`. Nós estudamos a associação entre as variáveis `sex` e `statusquo`. Vamos, então, fazer um teste de significância para testar a diferença
entre as médidas de `statusquo` para homens e mulheres. 

```{r message=FALSE, R.options=list(digits=3)}
Chile <- read.delim("C://Users//fsabino//Desktop//Codes//papers//Introductory_Stat_II//notebook//Chile.txt")
library(mosaic)
fv <- favstats(statusquo ~ sex, data = Chile)
fv
```

```{r echo=FALSE}
m1 <- fv[1, "mean"]
m2 <- fv[2, "mean"]
d <- m1 - m2
sd1 <- fv[1, "sd"]
sd2 <- fv[2, "sd"]
n1 <- fv[1, "n"] 
n2 <- fv[2, "n"]
ep_d <- sqrt( sd1^2/n1 + sd2^2/n2 )
t_obs <- d / ep_d
```

* Diferença:\ $d = `r round(m1, 4)` - (`r round(m2, 4)`) = `r round(d, 4)`$.
* Desvio padrão estimado:\ $s_1 = `r round(sd1, 4)`$ (mulheres) and  $s_2 = `r round(sd2, 4)`$ (homens). 
* Tamanhos amostrais:\ $n_1 = `r n1`$ e  $n_2 = `r n2`$.
* Erro padrão estimado da diferença:\  $ep_d = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} =
  \sqrt{\frac{`r round(sd1, 4)`^2}{`r n1`} + \frac{`r round(sd2, 4)`^2}{`r n2`}} = `r round(ep_d, 4)`$.
* $t$-escore observado para $H_0:\ \mu_1-\mu_2=0$ é: $\quad t_{obs} = \frac{d-0}{ep_d} = \frac{`r round(d, 4)`}{`r round(ep_d, 4)`} = `r round(t_obs, 4)`$.
* Como os tamanhos das amostras são "grandes", nós podemos usar o escore-$z$ ao invés do escore-$t$ para encontrar o $p$-valor aproximado:
```{r}
1 - pdist("norm", q = 3.4786, xlim = c(-4, 4))
```
* Então o $p$-valor é $2\cdot 0.00025 = 0.0005$, e, portanto, nós rejeitamos a hipótese nula.
* Podemos deixar todos os cálculos para o **R** usando `t.test`: 
```{r}
t.test(statusquo ~ sex, data = Chile)
```
* Nós reconhecemos o escore-$t$
  $3.4786$ e o $p$-valor $0.0005$. Os graus de liberdade 
  $df = 2679$ são grandes e neste caso os resultados obtidos utilizando os escores-$z$ e $t$ são muito similares.



## Comparação entre duas médias: intervalo de confiança (amostras independentes)
* Nós já temos todos os "ingredientes" para construir um
  **intervalo de confiança para $\mu_2-\mu_1$**:
    * $d=\bar{y}_2-\bar{y}_1$ é um estimador por pornto para $\mu_2-\mu_1$.
    * $ep_d=\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$ é um estimador por ponto para o erro padrão de $d$.
* Then: 
  $$
  d\pm t_{crit}ep_d
  $$ 
  é um intervalo de confiança para $\mu_2-\mu_1$.
* O escore-$t$ crítico, $t_{crit}$ é escolhido de acordo com o nível de confiança desejado. 
<!-- Se $n_1$ e $n_2$ both are greater than 30, then -->
<!--   $t_{crit} = 2$ yields a confidence level of approximately 95\%. -->



## Comparação entre duas médias: teste-$t$ pareado (amostras dependentes)

* Experimento:
    * Você escolhe $10$ supermercados Zaffari/Nacional (ou outro) aleatoriamente, e mede o tempo médio de serviço das caixas registradoras durante algum período de tempo.
    * Agora, novas caixas registradoras são instaladas nos $10$ supermercados e você repete o experimento. 
* É interessante investigar se as novas caixas registradoras mudaram ou não o tempo médio de serviço.
* Portanto, nós temos 2 amostras correspondentes à tecnologia nova e antiga. Neste caso, as amostras são **dependentes**, já que temos duas medições em cada loja (assuma que outras variáveis sejam mantidas fixas).
* Usamos a seguinte estratégia para análise:
    * Para cada loja calcule **a mudança** no tempo médio de serviço quando mudamos da tecnologia antiga para a nova.
    * As alterações $d_1,d_2,\ldots,d_{10}$ formam 
      **UMA** amostra de uma população com média $\mu$.
    * Teste a hipótese $H_0: \mu=0$ como de costume (usando um teste-$t$-test para testar a média). 

----

### Exemplo do Supermercado
* Os dados são organizados em um "data frame" com 2 variáveis, `before`
e `after`, contendo o tempo médio de serviço antes e depois da instalação da nova tecnologia. Ao invés de fazer cálculos manuais, nós deixamos o **R** executar o teste de significância (usando `t.test` com `paired = TRUE` dado que as nossas amostras são emparelhadas/dependentes):
```{r}
super <- read.delim("C://Users//fsabino//Desktop//Codes//papers//Introductory_Stat_II//notebook//supermarket.txt")
head(super, n = 3)
t.test(super$before, super$after, paired = TRUE)
```
* Com um $p$-valor de $0.00029$, nós rejeitamos que o tempo médio de serviço seja o mesmo após a instalação da nova tecnologia.

# Comparação de duas proporções
## Comparação de duas proporções
* Considere a situação em que temos amostras de duas variáveis qualitativas e queremos investigar se uma determinada propriedade está presente ou não:
    * Seja a proporção da população $1$ igual $p_1$, estimada por $\hat{p}_1$ com base em uma amostra de tamanho $n_1$.
    * Seja a proporção da população 2 igual $p_2$, estimada por $\hat{p}_2$ com base em uma amostra de tamanho $n_2$.
    * Nós estamos interessados na diferença $p_2-p_1$, que é estimada por $d=\hat{p}_2-\hat{p}_1$.
    * Calculando o **erro padrão estimado**
      $ep_d$ da diferença, nós podemos:
* Construir um
    * intervalo de confiança aproximado para a diferença, $p_2 - p_1$.
    * um teste de significância. 



## Comparação de duas proporções: Amostras independentes
* Na situação em que temos amostras independentes, nós sabemos que
  $$
  ep_d=\sqrt{ep_1^2+ep_2^2},
  $$
  onde $ep_1$ e $ep_2$ são os erros padrão estimados para as proporções amostrais na população $1$ e 2, respectivamente.
* Relembre que estes erros padrão são $ep=\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$, e, portanto,
  $$
  ep_d = \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1}+\frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}.
  $$
* Um intervalo de confiança (aproximado) para $p_2-p_1$ é obtido pela construção usual:   
  $$
  (\hat{p}_2-\hat{p}_1)\pm z_{crit}ep_d,
  $$ 
  onde o escore-$z$ crítico determina o nível de confiança.


## Teste aproximado para comparar duas proporções (amostras independentes)

* Considere a hipótese nula $H_0$: $p_1=p_2$ (equivalentemente 
  $H_0: p_1 - p_2 = 0$) e a hipótese alternativa $H_1$: $p_1 \neq p_2$.
* Assumindo que $H_0$ é verdadeira, nós temos uma proporção comum $p$, que é estimada por
  $$
  \hat{p}=\frac{n_1\hat{p}_1+n_2\hat{p}_2}{n_1+n_2},
  $$ 
  i.e. nós agregamos as populações e calculamos a frequência relativa da propriedade (em outras palavras: nós estimamos a proporção, $p$, como se as duas amostras fossem uma só).
* Em vez de usar o erro padrão estimado da diferença como anteriormente, nós estimamos da seguinte maneira sob $H_0$:
  $$
  ep_0=\sqrt{\hat{p}(1-\hat{p})\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}
  $$
* A estatística de teste observada (escore-$z$) sob $H_0$ é então:
  $$
  z_{obs}=\frac{\hat{p}_2-\hat{p}_1}{ep_0}.
  $$ 
<!-- * O $p$-valor is calculated in the usual way. -->

**ATENçÃO**: A aproximação só será boa se o tamanho da amostra for grande o suficiente. Costuma-se considerar como tal quando $n_1\hat{p},\
n_1(1-\hat{p}),\ n_2\hat{p},\ n_2(1-\hat{p})$ são todos maiores do que 5.



## Exemplo: Intervalo de confiança aproximado e teste para comparação de proporções

Voltemos ao conjunto de dados do `Chile`. Seja uma variável binária indicando se a pessoa pretende votar não (no **R**  devemos informar que se trata de um fator - `factor`):
```{r}
Chile$voteNo <- relevel(factor(Chile$vote == "N"), ref = "TRUE")
```

Nós estudamos a associação entre as variáveis `sex` e `voteNo`:
```{r}
tab <- tally( ~ sex + voteNo, data = Chile, useNA = "no")
tab
```
Isto nos dá todos os ingredientes necessários para fazer o teste de hipóteses:

* proporção estimada de homens que votam não:\ $\hat{p}_1=\frac{526}{526+697}=0.430$
* proporção estimada de mulheres que votam não:\ $\hat{p}_2=\frac{363}{363+946}=0.277$ 
* proporção comum estimada:\ $\hat{p}=\frac{1223 \times 0.430 + 1309 \times 0.277}{1309+1223}=\frac{526 + 363}{1309+1223}=0.351.$
* diferença estimada $d=\hat{p}_2-\hat{p}_1=0.277-0.430=-0.153$

Além disso, 

* Erro padrão da diferença:\
  $ep_d=\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1}+\frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}
      = \sqrt{\frac{0.430(1-0.430)}{1223}+\frac{0.277(1-0.277)}{1309}}= 0.0188$.
* Intervalo de confiança (aproximado) 95\% para a diferença:\ $d\pm
  1.96ep_d=(-0.190, -0.116)$.
* Erro padrão da diferença quando $H_0:\ p_1=p_2$ 
é verdadeira:\
  $ep_0=\sqrt{\hat{p}(1-\hat{p})(\frac{1}{n_1}+\frac{1}{n_2})} = 0.0190$.
* A estatística de teste observada/escore-$z$ é:\ $z_{obs}=\frac{d}{ep_0}=-8.06$. O teste para $H_0$ versus $H_1:
  p_1\not=p_2$ encontra um $p$-valor que é praticamente zero,
  i.e.\ podemos rejeitar que as proporções sejam iguais (com base nesta amostra temos fortes evidências de que elas não são iguais). 

### Cálculo automático no **R**

```{r}
Chile2 <- subset(Chile, !is.na(voteNo))
prop.test(voteNo ~ sex, data = Chile2, correct = FALSE)
```



## Teste exato de Fisher
* Se $n_1\hat{p},\ n_1(1-\hat{p}),\ n_2\hat{p},\ n_2(1-\hat{p})$ não são todos maiores do que 5, então o teste aproximado não é confiável. Ao invés disso, você pode usar o teste exato de Fisher:

```{r}
fisher.test(tab)
```

* O $p$-valor é extremamente pequeno, rejeitando definitivamente a hipótese nula de igualdade de proporções entre homens e mulheres.

## Visão geral da comparação de 2 grupos

![](https://asta.math.aau.dk/static-files/asta/img/agrSummaryTwoGroups.jpg)

## Costa Neto

Continuaremos agora o estudo utilizando o capítulo 5 do livro do Costa Neto.

* Erros do Tipo I e II, Poder do Teste
* Testes de uma Média Populacional com $\sigma$ conhecido
* Testes de uma Média Populacional com $\sigma$ desconhecido
* Testes de uma variância populacional
* Testes de uma proporção populacional, Correção de Continuidade
* Comparação de duas Médias (Amostras Independentes - desvios conhecidos, desconhecidos - e Pareadas)
* Comparação de duas Variâncias
* Comparação de duas Proporções
* Intervalo de Confiança para a Diferença entre Parâmetros
* Tamanhos das amostras

Refaça os exemplos e pelo menos os exercícios com resposta resumida no final do livro: 3, 5, 7, 10, 14, 15, 16, 19, 25, 26, 34 e 35.


## Resumo

Ao final deste estudo você deve:

* Saber definir qual a hipótese nula relevante e a alternativa correspondente
* Escolher adequadamente e calcular a estatística de teste
* Calcular o p-valor, interpretá-lo e estar apto para tomar a decisão e concluir a análise
* Calcular e interpretar os intervalos de confiança 
* Determinar o tamanho da amostra quando a amostragem é aleatória simples